{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Phase 7.1: Deep Learning with PyTorch\n\nThis notebook builds neural networks for diabetes prediction from scratch, explaining each concept along the way.\n\n## Learning Objectives\n1. Understand PyTorch tensors and data loading\n2. Build a neural network architecture\n3. Implement training loop with backpropagation\n4. Apply regularization (dropout, batch normalization)\n5. Evaluate and compare with our LightGBM baseline\n6. **Build a regression model** for HbA1c prediction\n7. **Use learning rate scheduling** to improve training\n8. **Apply Optuna** for hyperparameter optimization"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Setup and Data Loading\n",
    "\n",
    "### 1.1 Imports\n",
    "\n",
    "PyTorch is organized into several key modules:\n",
    "- `torch`: Core tensor operations (like NumPy)\n",
    "- `torch.nn`: Neural network layers and loss functions\n",
    "- `torch.optim`: Optimizers (SGD, Adam, etc.)\n",
    "- `torch.utils.data`: Data loading utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, roc_auc_score\n",
    "\n",
    "# PyTorch imports\n",
    "import torch\n",
    "import torch.nn as nn  # Neural network modules\n",
    "import torch.optim as optim  # Optimizers\n",
    "from torch.utils.data import DataLoader, TensorDataset  # Data utilities\n",
    "\n",
    "# Project setup\n",
    "project_root = Path.cwd().parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "# Check device (CPU vs GPU)\n",
    "# MPS = Metal Performance Shaders (Apple Silicon GPU)\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "    print(\"Using Apple Silicon GPU (MPS)\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print(\"Using NVIDIA GPU (CUDA)\")\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print(\"Using CPU\")\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Understanding Tensors\n",
    "\n",
    "**Tensors** are PyTorch's fundamental data structure - like NumPy arrays but with:\n",
    "- GPU acceleration support\n",
    "- Automatic differentiation (for backpropagation)\n",
    "\n",
    "Let's see a quick example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating tensors\n",
    "# From Python list\n",
    "x = torch.tensor([1, 2, 3])\n",
    "print(f\"Tensor from list: {x}\")\n",
    "print(f\"Shape: {x.shape}, Dtype: {x.dtype}\")\n",
    "\n",
    "# From NumPy (common in ML)\n",
    "np_array = np.array([[1.0, 2.0], [3.0, 4.0]])\n",
    "tensor_from_np = torch.from_numpy(np_array)\n",
    "print(f\"\\nTensor from NumPy:\\n{tensor_from_np}\")\n",
    "\n",
    "# Key difference: tensors track gradients for backpropagation\n",
    "x_with_grad = torch.tensor([1.0, 2.0, 3.0], requires_grad=True)\n",
    "print(f\"\\nTensor with gradient tracking: {x_with_grad}\")\n",
    "print(f\"requires_grad: {x_with_grad.requires_grad}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Load Our Data\n",
    "\n",
    "We'll use the **full imputation** dataset (no NaN) since neural networks can't handle missing values natively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "DATA_DIR = project_root / 'data' / 'processed'\n",
    "\n",
    "# Using 'with_labs_full' - complete data with lab values\n",
    "X = pd.read_parquet(DATA_DIR / 'X_with_labs_full.parquet')\n",
    "y = pd.read_parquet(DATA_DIR / 'y_with_labs_minimal.parquet')['DIABETES_STATUS']\n",
    "\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")\n",
    "print(f\"\\nTarget distribution:\")\n",
    "print(y.value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Data Splitting and Scaling\n",
    "\n",
    "**Why scale for neural networks?**\n",
    "\n",
    "Neural networks use gradient descent to learn. If features have very different scales:\n",
    "- Feature A: 0-1 (e.g., gender)\n",
    "- Feature B: 0-10000 (e.g., calories)\n",
    "\n",
    "The gradients for Feature B will dominate, making training unstable. StandardScaler transforms all features to mean=0, std=1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split: 70% train, 15% val, 15% test (same as Phase 7)\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "    X, y, test_size=0.15, random_state=42, stratify=y\n",
    ")\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.176, random_state=42, stratify=y_temp  # 0.176 * 0.85 ≈ 0.15\n",
    ")\n",
    "\n",
    "print(f\"Train: {len(X_train)} samples\")\n",
    "print(f\"Val:   {len(X_val)} samples\")\n",
    "print(f\"Test:  {len(X_test)} samples\")\n",
    "\n",
    "# Scale features\n",
    "# IMPORTANT: Fit scaler on training data only, then transform all sets\n",
    "# This prevents \"data leakage\" - test data shouldn't influence training\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)  # fit + transform\n",
    "X_val_scaled = scaler.transform(X_val)          # transform only\n",
    "X_test_scaled = scaler.transform(X_test)        # transform only\n",
    "\n",
    "print(f\"\\nAfter scaling:\")\n",
    "print(f\"Train mean: {X_train_scaled.mean():.6f}, std: {X_train_scaled.std():.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Convert to PyTorch Tensors and Create DataLoaders\n",
    "\n",
    "**DataLoader** is PyTorch's way of:\n",
    "1. Batching data (processing chunks at a time)\n",
    "2. Shuffling (randomizing order each epoch)\n",
    "3. Efficient memory management\n",
    "\n",
    "**Why batching?**\n",
    "- Using all 8000+ samples at once requires lots of memory\n",
    "- Smaller batches = noisier gradients = can help escape local minima\n",
    "- Typical batch sizes: 32, 64, 128, 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Convert to PyTorch tensors\n# Note: PyTorch expects float32 for features, long (int64) for class labels\nX_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32)\ny_train_tensor = torch.tensor(y_train.values, dtype=torch.long)\n\nX_val_tensor = torch.tensor(X_val_scaled, dtype=torch.float32)\ny_val_tensor = torch.tensor(y_val.values, dtype=torch.long)\n\nX_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32)\ny_test_tensor = torch.tensor(y_test.values, dtype=torch.long)\n\nprint(f\"Train tensor shape: {X_train_tensor.shape}\")\nprint(f\"Train tensor dtype: {X_train_tensor.dtype}\")\n\n# Create TensorDatasets (pairs features with labels)\ntrain_dataset = TensorDataset(X_train_tensor, y_train_tensor)\nval_dataset = TensorDataset(X_val_tensor, y_val_tensor)\ntest_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n\n# Create DataLoaders\nBATCH_SIZE = 64\n\n# drop_last=True for training: drops incomplete final batch\n# This prevents BatchNorm errors when last batch has only 1 sample\ntrain_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)\nval_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\ntest_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n\nprint(f\"\\nNumber of batches per epoch: {len(train_loader)}\")\nprint(f\"Batch size: {BATCH_SIZE}\")\nprint(f\"Total samples: {len(train_loader) * BATCH_SIZE} (approx)\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see what one batch looks like\n",
    "sample_batch_X, sample_batch_y = next(iter(train_loader))\n",
    "print(f\"Batch features shape: {sample_batch_X.shape}\")  # [batch_size, n_features]\n",
    "print(f\"Batch labels shape: {sample_batch_y.shape}\")    # [batch_size]\n",
    "print(f\"Batch labels: {sample_batch_y[:10]}\")           # First 10 labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Building the Neural Network\n",
    "\n",
    "### 2.1 Neural Network Architecture Basics\n",
    "\n",
    "A neural network is a series of **layers** that transform input data:\n",
    "\n",
    "```\n",
    "Input (96 features)\n",
    "    ↓\n",
    "Linear Layer (96 → 128) + ReLU activation\n",
    "    ↓\n",
    "Linear Layer (128 → 64) + ReLU activation\n",
    "    ↓\n",
    "Linear Layer (64 → 3)   # 3 output classes\n",
    "    ↓\n",
    "Output (3 class probabilities)\n",
    "```\n",
    "\n",
    "**Key components:**\n",
    "- **Linear layer**: y = Wx + b (matrix multiplication + bias)\n",
    "- **Activation function**: Adds non-linearity (ReLU, tanh, sigmoid)\n",
    "- **Why non-linearity?** Without it, stacking linear layers = one big linear layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize activation functions\n",
    "x = torch.linspace(-5, 5, 100)\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(12, 3))\n",
    "\n",
    "# ReLU: max(0, x) - most common, simple and effective\n",
    "axes[0].plot(x.numpy(), torch.relu(x).numpy())\n",
    "axes[0].set_title('ReLU: max(0, x)')\n",
    "axes[0].axhline(y=0, color='k', linestyle='-', linewidth=0.5)\n",
    "axes[0].axvline(x=0, color='k', linestyle='-', linewidth=0.5)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Sigmoid: 1/(1+e^-x) - squashes to (0,1), used for binary classification\n",
    "axes[1].plot(x.numpy(), torch.sigmoid(x).numpy())\n",
    "axes[1].set_title('Sigmoid: 1/(1+e^-x)')\n",
    "axes[1].axhline(y=0.5, color='r', linestyle='--', linewidth=0.5)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# Tanh: (e^x - e^-x)/(e^x + e^-x) - squashes to (-1,1)\n",
    "axes[2].plot(x.numpy(), torch.tanh(x).numpy())\n",
    "axes[2].set_title('Tanh: (e^x - e^-x)/(e^x + e^-x)')\n",
    "axes[2].axhline(y=0, color='k', linestyle='-', linewidth=0.5)\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Define Our Network Architecture\n",
    "\n",
    "In PyTorch, we define networks as classes that inherit from `nn.Module`:\n",
    "- `__init__`: Define the layers\n",
    "- `forward`: Define how data flows through layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiabetesClassifier(nn.Module):\n",
    "    \"\"\"\n",
    "    A simple feedforward neural network for diabetes classification.\n",
    "    \n",
    "    Architecture:\n",
    "        Input (n_features)\n",
    "        → Linear(128) → BatchNorm → ReLU → Dropout\n",
    "        → Linear(64) → BatchNorm → ReLU → Dropout  \n",
    "        → Linear(32) → BatchNorm → ReLU → Dropout\n",
    "        → Linear(3) → Output (class logits)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, n_features, n_classes=3, dropout_rate=0.3):\n",
    "        super().__init__()  # Initialize parent class\n",
    "        \n",
    "        # Layer 1: Input → 128 neurons\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Linear(n_features, 128),  # Linear transformation\n",
    "            nn.BatchNorm1d(128),          # Normalize activations (stabilizes training)\n",
    "            nn.ReLU(),                    # Activation function\n",
    "            nn.Dropout(dropout_rate)      # Randomly zero out neurons (prevents overfitting)\n",
    "        )\n",
    "        \n",
    "        # Layer 2: 128 → 64 neurons\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Linear(128, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate)\n",
    "        )\n",
    "        \n",
    "        # Layer 3: 64 → 32 neurons\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Linear(64, 32),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate)\n",
    "        )\n",
    "        \n",
    "        # Output layer: 32 → 3 classes (no activation - CrossEntropyLoss handles softmax)\n",
    "        self.output = nn.Linear(32, n_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass: define how data flows through the network.\n",
    "        \n",
    "        Args:\n",
    "            x: Input tensor of shape [batch_size, n_features]\n",
    "        \n",
    "        Returns:\n",
    "            Tensor of shape [batch_size, n_classes] (logits, not probabilities)\n",
    "        \"\"\"\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "\n",
    "# Create the model\n",
    "n_features = X_train_scaled.shape[1]\n",
    "model = DiabetesClassifier(n_features=n_features, n_classes=3, dropout_rate=0.3)\n",
    "\n",
    "# Move model to GPU if available\n",
    "model = model.to(device)\n",
    "\n",
    "print(model)\n",
    "print(f\"\\nModel is on: {next(model.parameters()).device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count parameters (weights and biases)\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"Total parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "\n",
    "# Let's break this down:\n",
    "print(\"\\nParameter breakdown:\")\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"  {name}: {param.shape} = {param.numel():,} params\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Understanding the Components\n",
    "\n",
    "**BatchNorm (Batch Normalization):**\n",
    "- Normalizes layer inputs to have mean≈0, std≈1\n",
    "- Speeds up training and allows higher learning rates\n",
    "- Acts as mild regularization\n",
    "\n",
    "**Dropout:**\n",
    "- During training: randomly sets neurons to 0 with probability p\n",
    "- Forces network to not rely on any single neuron\n",
    "- Prevents overfitting (like ensemble of smaller networks)\n",
    "- During evaluation: all neurons active (scaled by 1-p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate dropout\n",
    "dropout = nn.Dropout(p=0.5)  # 50% dropout\n",
    "\n",
    "test_input = torch.ones(1, 10)  # 10 values, all 1.0\n",
    "\n",
    "# Training mode: some values become 0\n",
    "dropout.train()\n",
    "print(\"Training mode (50% dropout):\")\n",
    "print(dropout(test_input))\n",
    "\n",
    "# Eval mode: all values kept (scaled)\n",
    "dropout.eval()\n",
    "print(\"\\nEval mode (no dropout):\")\n",
    "print(dropout(test_input))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Training the Network\n",
    "\n",
    "### 3.1 Loss Function and Optimizer\n",
    "\n",
    "**Loss Function (CrossEntropyLoss):**\n",
    "- Measures how wrong our predictions are\n",
    "- For classification: combines LogSoftmax + NLLLoss\n",
    "- Lower loss = better predictions\n",
    "\n",
    "**Optimizer (Adam):**\n",
    "- Updates weights to minimize loss\n",
    "- Adam = Adaptive Moment Estimation\n",
    "- Combines momentum + per-parameter learning rates\n",
    "- Usually works well with default settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function\n",
    "# CrossEntropyLoss expects:\n",
    "#   - Input: [batch_size, n_classes] (raw logits)\n",
    "#   - Target: [batch_size] (class indices 0, 1, 2)\n",
    "\n",
    "# Handle class imbalance with weights\n",
    "# More weight on minority classes = larger penalty for getting them wrong\n",
    "class_counts = y_train.value_counts().sort_index()\n",
    "class_weights = 1.0 / class_counts.values\n",
    "class_weights = class_weights / class_weights.sum() * len(class_weights)  # Normalize\n",
    "class_weights_tensor = torch.tensor(class_weights, dtype=torch.float32).to(device)\n",
    "\n",
    "print(\"Class distribution:\")\n",
    "print(class_counts)\n",
    "print(f\"\\nClass weights: {class_weights_tensor}\")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights_tensor)\n",
    "\n",
    "# Optimizer\n",
    "# Learning rate: how big steps to take when updating weights\n",
    "# Too high: overshoot optimal values\n",
    "# Too low: slow convergence\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 The Training Loop\n",
    "\n",
    "Neural network training follows this pattern for each batch:\n",
    "\n",
    "1. **Forward pass**: Run data through network → get predictions\n",
    "2. **Calculate loss**: Compare predictions to true labels\n",
    "3. **Backward pass**: Calculate gradients (how each weight affects loss)\n",
    "4. **Update weights**: Adjust weights to reduce loss\n",
    "5. **Zero gradients**: Reset for next iteration\n",
    "\n",
    "One pass through all batches = one **epoch**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, train_loader, criterion, optimizer, device):\n",
    "    \"\"\"\n",
    "    Train the model for one epoch.\n",
    "    \n",
    "    Returns:\n",
    "        Average loss for the epoch\n",
    "    \"\"\"\n",
    "    model.train()  # Set to training mode (enables dropout, updates BatchNorm)\n",
    "    total_loss = 0\n",
    "    \n",
    "    for batch_X, batch_y in train_loader:\n",
    "        # Move data to device (GPU if available)\n",
    "        batch_X = batch_X.to(device)\n",
    "        batch_y = batch_y.to(device)\n",
    "        \n",
    "        # Step 1: Zero gradients from previous iteration\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Step 2: Forward pass\n",
    "        outputs = model(batch_X)  # [batch_size, 3]\n",
    "        \n",
    "        # Step 3: Calculate loss\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        \n",
    "        # Step 4: Backward pass (compute gradients)\n",
    "        loss.backward()\n",
    "        \n",
    "        # Step 5: Update weights\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    return total_loss / len(train_loader)\n",
    "\n",
    "\n",
    "def evaluate(model, data_loader, criterion, device):\n",
    "    \"\"\"\n",
    "    Evaluate the model on a dataset.\n",
    "    \n",
    "    Returns:\n",
    "        loss, accuracy, predictions, true_labels\n",
    "    \"\"\"\n",
    "    model.eval()  # Set to evaluation mode (disables dropout, freezes BatchNorm)\n",
    "    total_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_probs = []\n",
    "    \n",
    "    with torch.no_grad():  # Disable gradient computation (faster, less memory)\n",
    "        for batch_X, batch_y in data_loader:\n",
    "            batch_X = batch_X.to(device)\n",
    "            batch_y = batch_y.to(device)\n",
    "            \n",
    "            outputs = model(batch_X)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            # Get predictions (class with highest logit)\n",
    "            probs = torch.softmax(outputs, dim=1)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            \n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(batch_y.cpu().numpy())\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "    \n",
    "    avg_loss = total_loss / len(data_loader)\n",
    "    accuracy = np.mean(np.array(all_preds) == np.array(all_labels))\n",
    "    \n",
    "    return avg_loss, accuracy, np.array(all_preds), np.array(all_labels), np.array(all_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Training with Early Stopping\n",
    "\n",
    "**Early stopping** prevents overfitting by:\n",
    "1. Monitoring validation loss after each epoch\n",
    "2. Saving the model when validation loss improves\n",
    "3. Stopping if no improvement for N epochs (\"patience\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training configuration\n",
    "N_EPOCHS = 100\n",
    "PATIENCE = 10  # Stop if no improvement for 10 epochs\n",
    "\n",
    "# Track metrics\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "val_accuracies = []\n",
    "\n",
    "# Early stopping variables\n",
    "best_val_loss = float('inf')\n",
    "best_model_state = None\n",
    "patience_counter = 0\n",
    "\n",
    "print(\"Starting training...\")\n",
    "print(f\"{'Epoch':>6} {'Train Loss':>12} {'Val Loss':>12} {'Val Acc':>10} {'Status':>10}\")\n",
    "print(\"-\" * 55)\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    # Train\n",
    "    train_loss = train_one_epoch(model, train_loader, criterion, optimizer, device)\n",
    "    train_losses.append(train_loss)\n",
    "    \n",
    "    # Evaluate\n",
    "    val_loss, val_acc, _, _, _ = evaluate(model, val_loader, criterion, device)\n",
    "    val_losses.append(val_loss)\n",
    "    val_accuracies.append(val_acc)\n",
    "    \n",
    "    # Early stopping check\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_model_state = model.state_dict().copy()  # Save best model\n",
    "        patience_counter = 0\n",
    "        status = \"✓ Best\"\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        status = f\"({patience_counter}/{PATIENCE})\"\n",
    "    \n",
    "    # Print progress every 5 epochs\n",
    "    if (epoch + 1) % 5 == 0 or patience_counter == 0:\n",
    "        print(f\"{epoch+1:>6} {train_loss:>12.4f} {val_loss:>12.4f} {val_acc:>10.4f} {status:>10}\")\n",
    "    \n",
    "    # Stop if no improvement\n",
    "    if patience_counter >= PATIENCE:\n",
    "        print(f\"\\nEarly stopping at epoch {epoch+1}\")\n",
    "        break\n",
    "\n",
    "# Load best model\n",
    "model.load_state_dict(best_model_state)\n",
    "print(f\"\\nLoaded best model (val_loss: {best_val_loss:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training curves\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Loss curves\n",
    "axes[0].plot(train_losses, label='Train Loss')\n",
    "axes[0].plot(val_losses, label='Val Loss')\n",
    "axes[0].axvline(x=np.argmin(val_losses), color='r', linestyle='--', label='Best Model')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Loss')\n",
    "axes[0].set_title('Training and Validation Loss')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Accuracy curve\n",
    "axes[1].plot(val_accuracies, label='Val Accuracy', color='green')\n",
    "axes[1].axvline(x=np.argmin(val_losses), color='r', linestyle='--', label='Best Model')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Accuracy')\n",
    "axes[1].set_title('Validation Accuracy')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Evaluation\n",
    "\n",
    "### 4.1 Test Set Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "test_loss, test_acc, y_pred, y_true, y_probs = evaluate(model, test_loader, criterion, device)\n",
    "\n",
    "# Calculate metrics\n",
    "f1_macro = f1_score(y_true, y_pred, average='macro')\n",
    "roc_auc = roc_auc_score(y_true, y_probs, multi_class='ovr')\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"TEST SET RESULTS\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Accuracy:  {test_acc:.4f}\")\n",
    "print(f\"F1 Macro:  {f1_macro:.4f}\")\n",
    "print(f\"ROC AUC:   {roc_auc:.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_true, y_pred, target_names=['No Diabetes', 'Prediabetes', 'Diabetes']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "from src.models.evaluate import plot_confusion_matrix\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "plot_confusion_matrix(y_true, y_pred, ax=axes[0], title='PyTorch Model - Confusion Matrix')\n",
    "plot_confusion_matrix(y_true, y_pred, ax=axes[1], normalize=True, title='Normalized')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Compare with LightGBM Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Phase 7 results for comparison\n",
    "import json\n",
    "\n",
    "results_path = project_root / 'models' / 'advanced' / 'results_summary.json'\n",
    "with open(results_path) as f:\n",
    "    phase7_results = json.load(f)\n",
    "\n",
    "print(\"Model Comparison (Test Set):\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"{'Model':<30} {'F1 Macro':>10} {'ROC AUC':>10} {'Accuracy':>10}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# LightGBM results\n",
    "lgb_results = phase7_results['classification']['test']['LightGBM (with labs)']\n",
    "print(f\"{'LightGBM (with labs)':<30} {lgb_results['f1_macro']:>10.4f} {lgb_results['roc_auc_ovr']:>10.4f} {lgb_results['accuracy']:>10.4f}\")\n",
    "\n",
    "# MLP (sklearn) results\n",
    "mlp_results = phase7_results['classification']['test']['MLP (with labs)']\n",
    "print(f\"{'MLP sklearn (with labs)':<30} {mlp_results['f1_macro']:>10.4f} {mlp_results['roc_auc_ovr']:>10.4f} {mlp_results['accuracy']:>10.4f}\")\n",
    "\n",
    "# PyTorch results\n",
    "print(f\"{'PyTorch NN (with labs)':<30} {f1_macro:>10.4f} {roc_auc:>10.4f} {test_acc:>10.4f}\")\n",
    "print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "import joblib\n",
    "\n",
    "save_dir = project_root / 'models' / 'advanced' / 'classification'\n",
    "\n",
    "# Save PyTorch model state\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'n_features': n_features,\n",
    "    'n_classes': 3,\n",
    "    'dropout_rate': 0.3,\n",
    "    'scaler': scaler,\n",
    "    'metrics': {\n",
    "        'test_accuracy': test_acc,\n",
    "        'test_f1_macro': f1_macro,\n",
    "        'test_roc_auc': roc_auc\n",
    "    }\n",
    "}, save_dir / 'pytorch_with_labs.pt')\n",
    "\n",
    "print(f\"Model saved to {save_dir / 'pytorch_with_labs.pt'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "---\n\n## Part 6: Regression - Predicting HbA1c\n\nNow let's tackle **regression**: predicting the actual HbA1c value (continuous) instead of diabetes class (categorical).\n\n### Key Differences from Classification:\n| Aspect | Classification | Regression |\n|--------|---------------|------------|\n| Output | 3 class probabilities | 1 continuous value |\n| Loss function | CrossEntropyLoss | MSELoss (Mean Squared Error) |\n| Output activation | None (softmax in loss) | None (direct prediction) |\n| Metrics | F1, Accuracy, ROC AUC | RMSE, MAE, R² |",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "### 6.1 Load Regression Target (HbA1c)",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Load HbA1c target for regression\n# HbA1c is stored in study_population, not in processed y files\nINTERIM_DIR = project_root / 'data' / 'interim'\nstudy_pop = pd.read_parquet(INTERIM_DIR / 'study_population.parquet')\n\n# Get HbA1c values aligned with our feature indices\ny_reg = study_pop.loc[y.index, 'LBXGH']\n\n# Check for missing values\nprint(f\"HbA1c (LBXGH) statistics:\")\nprint(f\"  Shape: {y_reg.shape}\")\nprint(f\"  Missing: {y_reg.isna().sum()} ({y_reg.isna().mean()*100:.1f}%)\")\nprint(f\"  Range: {y_reg.min():.1f} - {y_reg.max():.1f}%\")\nprint(f\"  Mean: {y_reg.mean():.2f}%, Median: {y_reg.median():.2f}%\")\n\n# Distribution plot\nfig, ax = plt.subplots(figsize=(8, 4))\ny_reg.dropna().hist(bins=50, ax=ax, edgecolor='black', alpha=0.7)\nax.axvline(x=5.7, color='orange', linestyle='--', label='Prediabetes threshold (5.7%)')\nax.axvline(x=6.5, color='red', linestyle='--', label='Diabetes threshold (6.5%)')\nax.set_xlabel('HbA1c (%)')\nax.set_ylabel('Count')\nax.set_title('HbA1c Distribution')\nax.legend()\nplt.tight_layout()\nplt.show()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### 6.2 Prepare Regression Data\n\nWe need to:\n1. Remove samples with missing HbA1c values\n2. Split data (using same indices as classification for fair comparison)\n3. Create new DataLoaders with float32 targets (not long/int64)",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Create mask for valid HbA1c values\nvalid_mask = ~y_reg.isna()\nprint(f\"Samples with valid HbA1c: {valid_mask.sum()} / {len(valid_mask)}\")\n\n# Get aligned data\nX_reg = X.loc[valid_mask]\ny_reg_valid = y_reg.loc[valid_mask]\n\n# Split regression data (same random state for comparability)\nX_reg_temp, X_reg_test, y_reg_temp, y_reg_test = train_test_split(\n    X_reg, y_reg_valid, test_size=0.15, random_state=42\n)\nX_reg_train, X_reg_val, y_reg_train, y_reg_val = train_test_split(\n    X_reg_temp, y_reg_temp, test_size=0.176, random_state=42\n)\n\nprint(f\"\\nRegression splits:\")\nprint(f\"  Train: {len(X_reg_train)}\")\nprint(f\"  Val:   {len(X_reg_val)}\")\nprint(f\"  Test:  {len(X_reg_test)}\")\n\n# Scale features (fit new scaler on regression training data)\nscaler_reg = StandardScaler()\nX_reg_train_scaled = scaler_reg.fit_transform(X_reg_train)\nX_reg_val_scaled = scaler_reg.transform(X_reg_val)\nX_reg_test_scaled = scaler_reg.transform(X_reg_test)\n\n# Convert to tensors - NOTE: y is float32 for regression, not long\nX_reg_train_t = torch.tensor(X_reg_train_scaled, dtype=torch.float32)\ny_reg_train_t = torch.tensor(y_reg_train.values, dtype=torch.float32).unsqueeze(1)  # [N, 1]\n\nX_reg_val_t = torch.tensor(X_reg_val_scaled, dtype=torch.float32)\ny_reg_val_t = torch.tensor(y_reg_val.values, dtype=torch.float32).unsqueeze(1)\n\nX_reg_test_t = torch.tensor(X_reg_test_scaled, dtype=torch.float32)\ny_reg_test_t = torch.tensor(y_reg_test.values, dtype=torch.float32).unsqueeze(1)\n\nprint(f\"\\nTensor shapes:\")\nprint(f\"  X_train: {X_reg_train_t.shape}, y_train: {y_reg_train_t.shape}\")\n\n# Create DataLoaders\nreg_train_dataset = TensorDataset(X_reg_train_t, y_reg_train_t)\nreg_val_dataset = TensorDataset(X_reg_val_t, y_reg_val_t)\nreg_test_dataset = TensorDataset(X_reg_test_t, y_reg_test_t)\n\nreg_train_loader = DataLoader(reg_train_dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)\nreg_val_loader = DataLoader(reg_val_dataset, batch_size=BATCH_SIZE, shuffle=False)\nreg_test_loader = DataLoader(reg_test_dataset, batch_size=BATCH_SIZE, shuffle=False)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### 6.3 Define Regression Model\n\nThe architecture is nearly identical to classification, but:\n- Output layer has **1 neuron** (not 3)\n- No activation on output (we want raw predicted value)\n- Loss function is **MSELoss** (not CrossEntropyLoss)",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "class DiabetesRegressor(nn.Module):\n    \"\"\"\n    Neural network for HbA1c prediction (regression).\n    \n    Same architecture as classifier, but with 1 output instead of 3.\n    \"\"\"\n    \n    def __init__(self, n_features, dropout_rate=0.3):\n        super().__init__()\n        \n        self.layer1 = nn.Sequential(\n            nn.Linear(n_features, 128),\n            nn.BatchNorm1d(128),\n            nn.ReLU(),\n            nn.Dropout(dropout_rate)\n        )\n        \n        self.layer2 = nn.Sequential(\n            nn.Linear(128, 64),\n            nn.BatchNorm1d(64),\n            nn.ReLU(),\n            nn.Dropout(dropout_rate)\n        )\n        \n        self.layer3 = nn.Sequential(\n            nn.Linear(64, 32),\n            nn.BatchNorm1d(32),\n            nn.ReLU(),\n            nn.Dropout(dropout_rate)\n        )\n        \n        # Single output for regression (no activation)\n        self.output = nn.Linear(32, 1)\n    \n    def forward(self, x):\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.output(x)\n        return x\n\n# Create model\nreg_model = DiabetesRegressor(n_features=n_features, dropout_rate=0.3).to(device)\n\n# Loss function: Mean Squared Error\n# Measures average squared difference between predictions and targets\nreg_criterion = nn.MSELoss()\n\n# Optimizer\nreg_optimizer = optim.Adam(reg_model.parameters(), lr=0.001)\n\nprint(reg_model)\nprint(f\"\\nTotal parameters: {sum(p.numel() for p in reg_model.parameters()):,}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### 6.4 Train Regression Model",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "def train_one_epoch_reg(model, train_loader, criterion, optimizer, device):\n    \"\"\"Train regression model for one epoch.\"\"\"\n    model.train()\n    total_loss = 0\n    \n    for batch_X, batch_y in train_loader:\n        batch_X = batch_X.to(device)\n        batch_y = batch_y.to(device)\n        \n        optimizer.zero_grad()\n        outputs = model(batch_X)\n        loss = criterion(outputs, batch_y)\n        loss.backward()\n        optimizer.step()\n        \n        total_loss += loss.item()\n    \n    return total_loss / len(train_loader)\n\n\ndef evaluate_reg(model, data_loader, criterion, device):\n    \"\"\"Evaluate regression model.\"\"\"\n    model.eval()\n    total_loss = 0\n    all_preds = []\n    all_labels = []\n    \n    with torch.no_grad():\n        for batch_X, batch_y in data_loader:\n            batch_X = batch_X.to(device)\n            batch_y = batch_y.to(device)\n            \n            outputs = model(batch_X)\n            loss = criterion(outputs, batch_y)\n            total_loss += loss.item()\n            \n            all_preds.extend(outputs.cpu().numpy().flatten())\n            all_labels.extend(batch_y.cpu().numpy().flatten())\n    \n    avg_loss = total_loss / len(data_loader)\n    \n    # Calculate RMSE\n    preds = np.array(all_preds)\n    labels = np.array(all_labels)\n    rmse = np.sqrt(np.mean((preds - labels) ** 2))\n    \n    return avg_loss, rmse, preds, labels",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Training loop for regression\nreg_train_losses = []\nreg_val_losses = []\nreg_val_rmses = []\n\nbest_reg_val_loss = float('inf')\nbest_reg_model_state = None\nreg_patience_counter = 0\n\nprint(\"Training Regression Model...\")\nprint(f\"{'Epoch':>6} {'Train Loss':>12} {'Val Loss':>12} {'Val RMSE':>10} {'Status':>10}\")\nprint(\"-\" * 55)\n\nfor epoch in range(N_EPOCHS):\n    train_loss = train_one_epoch_reg(reg_model, reg_train_loader, reg_criterion, reg_optimizer, device)\n    reg_train_losses.append(train_loss)\n    \n    val_loss, val_rmse, _, _ = evaluate_reg(reg_model, reg_val_loader, reg_criterion, device)\n    reg_val_losses.append(val_loss)\n    reg_val_rmses.append(val_rmse)\n    \n    if val_loss < best_reg_val_loss:\n        best_reg_val_loss = val_loss\n        best_reg_model_state = reg_model.state_dict().copy()\n        reg_patience_counter = 0\n        status = \"✓ Best\"\n    else:\n        reg_patience_counter += 1\n        status = f\"({reg_patience_counter}/{PATIENCE})\"\n    \n    if (epoch + 1) % 5 == 0 or reg_patience_counter == 0:\n        print(f\"{epoch+1:>6} {train_loss:>12.4f} {val_loss:>12.4f} {val_rmse:>10.4f} {status:>10}\")\n    \n    if reg_patience_counter >= PATIENCE:\n        print(f\"\\nEarly stopping at epoch {epoch+1}\")\n        break\n\nreg_model.load_state_dict(best_reg_model_state)\nprint(f\"\\nLoaded best model (val_loss: {best_reg_val_loss:.4f})\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### 6.5 Evaluate Regression Model",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n\n# Evaluate on test set\ntest_loss, test_rmse, y_reg_pred, y_reg_true = evaluate_reg(reg_model, reg_test_loader, reg_criterion, device)\n\n# Calculate additional metrics\ntest_mae = mean_absolute_error(y_reg_true, y_reg_pred)\ntest_r2 = r2_score(y_reg_true, y_reg_pred)\n\nprint(\"=\" * 50)\nprint(\"REGRESSION TEST SET RESULTS\")\nprint(\"=\" * 50)\nprint(f\"RMSE:  {test_rmse:.4f}\")\nprint(f\"MAE:   {test_mae:.4f}\")\nprint(f\"R²:    {test_r2:.4f}\")\n\n# Compare with LightGBM\nlgb_reg_results = phase7_results['regression']['test']['LightGBM (with labs)']\nmlp_reg_results = phase7_results['regression']['test']['MLP (with labs)']\n\nprint(\"\\n\" + \"=\" * 60)\nprint(\"Model Comparison - Regression (Test Set):\")\nprint(\"=\" * 60)\nprint(f\"{'Model':<30} {'RMSE':>10} {'MAE':>10} {'R²':>10}\")\nprint(\"-\" * 60)\nprint(f\"{'LightGBM (with labs)':<30} {lgb_reg_results['rmse']:>10.4f} {lgb_reg_results['mae']:>10.4f} {lgb_reg_results['r2']:>10.4f}\")\nprint(f\"{'MLP sklearn (with labs)':<30} {mlp_reg_results['rmse']:>10.4f} {mlp_reg_results['mae']:>10.4f} {mlp_reg_results['r2']:>10.4f}\")\nprint(f\"{'PyTorch NN (with labs)':<30} {test_rmse:>10.4f} {test_mae:>10.4f} {test_r2:>10.4f}\")\nprint(\"-\" * 60)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Visualize regression predictions\nfig, axes = plt.subplots(1, 2, figsize=(12, 5))\n\n# Predicted vs Actual\naxes[0].scatter(y_reg_true, y_reg_pred, alpha=0.3, s=10)\naxes[0].plot([4, 14], [4, 14], 'r--', label='Perfect prediction')\naxes[0].set_xlabel('Actual HbA1c (%)')\naxes[0].set_ylabel('Predicted HbA1c (%)')\naxes[0].set_title(f'Predicted vs Actual (R² = {test_r2:.3f})')\naxes[0].legend()\naxes[0].grid(True, alpha=0.3)\n\n# Residual plot\nresiduals = y_reg_pred - y_reg_true\naxes[1].scatter(y_reg_pred, residuals, alpha=0.3, s=10)\naxes[1].axhline(y=0, color='r', linestyle='--')\naxes[1].set_xlabel('Predicted HbA1c (%)')\naxes[1].set_ylabel('Residual (Predicted - Actual)')\naxes[1].set_title('Residual Plot')\naxes[1].grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.show()\n\nprint(f\"\\nResidual statistics:\")\nprint(f\"  Mean: {residuals.mean():.4f} (should be ~0)\")\nprint(f\"  Std:  {residuals.std():.4f}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "---\n\n## Part 7: Learning Rate Scheduling\n\n**Learning rate scheduling** adjusts the learning rate during training to improve convergence.\n\n### Why Schedule Learning Rate?\n- **High LR early**: Take big steps to quickly find good regions\n- **Low LR later**: Take small steps to fine-tune and not overshoot\n\n### Common Schedulers:\n| Scheduler | Description |\n|-----------|-------------|\n| **StepLR** | Multiply LR by gamma every N epochs |\n| **ReduceLROnPlateau** | Reduce LR when metric stops improving |\n| **CosineAnnealingLR** | Smoothly decrease LR following cosine curve |\n| **OneCycleLR** | Ramp up then down (often best for fast training) |\n\nWe'll use **OneCycleLR** - it's been shown to achieve faster convergence and often better results.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Visualize different learning rate schedules\nfrom torch.optim.lr_scheduler import StepLR, CosineAnnealingLR, OneCycleLR\n\n# Create dummy model and optimizer for visualization\ndummy_model = nn.Linear(10, 1)\nepochs = 50\nsteps_per_epoch = len(train_loader)\n\nfig, axes = plt.subplots(1, 3, figsize=(14, 4))\n\n# StepLR: decrease by 0.1 every 15 epochs\ndummy_opt = optim.Adam(dummy_model.parameters(), lr=0.01)\nscheduler = StepLR(dummy_opt, step_size=15, gamma=0.1)\nlrs = []\nfor _ in range(epochs):\n    lrs.append(dummy_opt.param_groups[0]['lr'])\n    scheduler.step()\naxes[0].plot(lrs)\naxes[0].set_title('StepLR (step=15, gamma=0.1)')\naxes[0].set_xlabel('Epoch')\naxes[0].set_ylabel('Learning Rate')\naxes[0].grid(True, alpha=0.3)\n\n# CosineAnnealingLR: smooth cosine decay\ndummy_opt = optim.Adam(dummy_model.parameters(), lr=0.01)\nscheduler = CosineAnnealingLR(dummy_opt, T_max=epochs)\nlrs = []\nfor _ in range(epochs):\n    lrs.append(dummy_opt.param_groups[0]['lr'])\n    scheduler.step()\naxes[1].plot(lrs)\naxes[1].set_title('CosineAnnealingLR')\naxes[1].set_xlabel('Epoch')\naxes[1].set_ylabel('Learning Rate')\naxes[1].grid(True, alpha=0.3)\n\n# OneCycleLR: warmup then decay\ndummy_opt = optim.Adam(dummy_model.parameters(), lr=0.01)\nscheduler = OneCycleLR(dummy_opt, max_lr=0.01, epochs=epochs, steps_per_epoch=steps_per_epoch)\nlrs = []\nfor _ in range(epochs * steps_per_epoch):\n    lrs.append(dummy_opt.param_groups[0]['lr'])\n    scheduler.step()\n# Plot per epoch (average)\nlrs_epoch = [np.mean(lrs[i*steps_per_epoch:(i+1)*steps_per_epoch]) for i in range(epochs)]\naxes[2].plot(lrs_epoch)\naxes[2].set_title('OneCycleLR (warmup + decay)')\naxes[2].set_xlabel('Epoch')\naxes[2].set_ylabel('Learning Rate')\naxes[2].grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.show()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### 7.1 Train Classification Model with OneCycleLR\n\nLet's retrain our classification model with learning rate scheduling and compare results.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "def train_with_scheduler(model, train_loader, val_loader, criterion, optimizer, scheduler, \n                         device, n_epochs, patience, task='classification'):\n    \"\"\"\n    Train model with learning rate scheduling.\n    \n    Key difference: scheduler.step() called after each BATCH for OneCycleLR.\n    \"\"\"\n    train_losses = []\n    val_losses = []\n    val_metrics = []\n    lrs = []\n    \n    best_val_loss = float('inf')\n    best_model_state = None\n    patience_counter = 0\n    \n    for epoch in range(n_epochs):\n        # Training\n        model.train()\n        epoch_loss = 0\n        \n        for batch_X, batch_y in train_loader:\n            batch_X = batch_X.to(device)\n            batch_y = batch_y.to(device)\n            \n            optimizer.zero_grad()\n            outputs = model(batch_X)\n            loss = criterion(outputs, batch_y)\n            loss.backward()\n            optimizer.step()\n            \n            # Step scheduler after each batch for OneCycleLR\n            scheduler.step()\n            \n            epoch_loss += loss.item()\n            lrs.append(optimizer.param_groups[0]['lr'])\n        \n        train_losses.append(epoch_loss / len(train_loader))\n        \n        # Validation\n        model.eval()\n        val_loss = 0\n        all_preds = []\n        all_labels = []\n        \n        with torch.no_grad():\n            for batch_X, batch_y in val_loader:\n                batch_X = batch_X.to(device)\n                batch_y = batch_y.to(device)\n                outputs = model(batch_X)\n                loss = criterion(outputs, batch_y)\n                val_loss += loss.item()\n                \n                if task == 'classification':\n                    preds = outputs.argmax(dim=1)\n                else:\n                    preds = outputs.flatten()\n                all_preds.extend(preds.cpu().numpy())\n                all_labels.extend(batch_y.cpu().numpy() if task == 'classification' \n                                  else batch_y.cpu().numpy().flatten())\n        \n        val_losses.append(val_loss / len(val_loader))\n        \n        # Calculate metric\n        if task == 'classification':\n            metric = f1_score(all_labels, all_preds, average='macro')\n        else:\n            metric = np.sqrt(np.mean((np.array(all_preds) - np.array(all_labels)) ** 2))\n        val_metrics.append(metric)\n        \n        # Early stopping\n        if val_losses[-1] < best_val_loss:\n            best_val_loss = val_losses[-1]\n            best_model_state = model.state_dict().copy()\n            patience_counter = 0\n            status = \"✓ Best\"\n        else:\n            patience_counter += 1\n            status = f\"({patience_counter}/{patience})\"\n        \n        if (epoch + 1) % 5 == 0 or patience_counter == 0:\n            metric_name = 'F1' if task == 'classification' else 'RMSE'\n            print(f\"{epoch+1:>4} | Train: {train_losses[-1]:.4f} | Val: {val_losses[-1]:.4f} | \"\n                  f\"{metric_name}: {metric:.4f} | LR: {lrs[-1]:.6f} | {status}\")\n        \n        if patience_counter >= patience:\n            print(f\"\\nEarly stopping at epoch {epoch+1}\")\n            break\n    \n    model.load_state_dict(best_model_state)\n    return train_losses, val_losses, val_metrics, lrs",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Create fresh model for fair comparison\nmodel_with_sched = DiabetesClassifier(n_features=n_features, n_classes=3, dropout_rate=0.3).to(device)\n\n# Optimizer\noptimizer_sched = optim.Adam(model_with_sched.parameters(), lr=0.001)\n\n# OneCycleLR scheduler\n# max_lr: peak learning rate (reached midway)\n# total_steps: total number of optimizer steps\nscheduler = OneCycleLR(\n    optimizer_sched,\n    max_lr=0.01,  # 10x base LR at peak\n    epochs=N_EPOCHS,\n    steps_per_epoch=len(train_loader),\n    pct_start=0.3,  # 30% warmup\n    anneal_strategy='cos'  # Cosine annealing\n)\n\nprint(\"Training with OneCycleLR...\")\nprint(\"=\" * 70)\n\nsched_train_losses, sched_val_losses, sched_val_f1s, sched_lrs = train_with_scheduler(\n    model_with_sched, train_loader, val_loader, criterion, optimizer_sched, scheduler,\n    device, N_EPOCHS, PATIENCE, task='classification'\n)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Compare training curves\nfig, axes = plt.subplots(1, 3, figsize=(15, 4))\n\n# Loss comparison\naxes[0].plot(val_losses, label='No Scheduler', alpha=0.7)\naxes[0].plot(sched_val_losses, label='OneCycleLR', alpha=0.7)\naxes[0].set_xlabel('Epoch')\naxes[0].set_ylabel('Validation Loss')\naxes[0].set_title('Validation Loss Comparison')\naxes[0].legend()\naxes[0].grid(True, alpha=0.3)\n\n# F1 comparison\naxes[1].plot(val_accuracies, label='No Scheduler (Acc)', alpha=0.7)\naxes[1].plot(sched_val_f1s, label='OneCycleLR (F1)', alpha=0.7)\naxes[1].set_xlabel('Epoch')\naxes[1].set_ylabel('Metric')\naxes[1].set_title('Validation Metric Comparison')\naxes[1].legend()\naxes[1].grid(True, alpha=0.3)\n\n# Learning rate\naxes[2].plot(sched_lrs)\naxes[2].set_xlabel('Training Step')\naxes[2].set_ylabel('Learning Rate')\naxes[2].set_title('OneCycleLR Learning Rate')\naxes[2].grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.show()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Evaluate model with scheduler on test set\n_, _, y_pred_sched, y_true_sched, y_probs_sched = evaluate(model_with_sched, test_loader, criterion, device)\n\nf1_sched = f1_score(y_true_sched, y_pred_sched, average='macro')\nroc_auc_sched = roc_auc_score(y_true_sched, y_probs_sched, multi_class='ovr')\nacc_sched = np.mean(y_pred_sched == y_true_sched)\n\nprint(\"=\" * 60)\nprint(\"Classification Comparison: With vs Without LR Scheduling\")\nprint(\"=\" * 60)\nprint(f\"{'Model':<35} {'F1 Macro':>10} {'ROC AUC':>10} {'Accuracy':>10}\")\nprint(\"-\" * 65)\nprint(f\"{'PyTorch (no scheduler)':<35} {f1_macro:>10.4f} {roc_auc:>10.4f} {test_acc:>10.4f}\")\nprint(f\"{'PyTorch (OneCycleLR)':<35} {f1_sched:>10.4f} {roc_auc_sched:>10.4f} {acc_sched:>10.4f}\")\nprint(f\"{'LightGBM (baseline)':<35} {lgb_results['f1_macro']:>10.4f} {lgb_results['roc_auc_ovr']:>10.4f} {lgb_results['accuracy']:>10.4f}\")\nprint(\"-\" * 65)\n\nimprovement = (f1_sched - f1_macro) / f1_macro * 100\nprint(f\"\\nLR Scheduling impact: {improvement:+.1f}% F1 change\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "---\n\n## Part 8: Hyperparameter Tuning with Optuna\n\n**Optuna** is a hyperparameter optimization framework that uses Bayesian optimization (TPE sampler) to efficiently search the hyperparameter space.\n\n### Why Optuna?\n- **Smarter than grid search**: Learns from previous trials to focus on promising regions\n- **Early pruning**: Can stop unpromising trials early, saving time\n- **Easy to use**: Define search space with simple `trial.suggest_*` calls\n\n### Hyperparameters we'll tune:\n| Parameter | Range | Description |\n|-----------|-------|-------------|\n| `n_layers` | 1-4 | Number of hidden layers |\n| `hidden_size` | 32-256 | Neurons per layer |\n| `dropout_rate` | 0.1-0.5 | Dropout probability |\n| `learning_rate` | 1e-4 to 1e-2 | Initial learning rate |\n| `batch_size` | 32, 64, 128 | Samples per batch |",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "import optuna\nfrom optuna.trial import TrialState\n\n# Suppress Optuna logging for cleaner output\noptuna.logging.set_verbosity(optuna.logging.WARNING)\n\nclass FlexibleNN(nn.Module):\n    \"\"\"\n    Flexible neural network where architecture is determined by hyperparameters.\n    \"\"\"\n    \n    def __init__(self, n_features, n_classes, hidden_sizes, dropout_rate):\n        super().__init__()\n        \n        layers = []\n        in_size = n_features\n        \n        for hidden_size in hidden_sizes:\n            layers.extend([\n                nn.Linear(in_size, hidden_size),\n                nn.BatchNorm1d(hidden_size),\n                nn.ReLU(),\n                nn.Dropout(dropout_rate)\n            ])\n            in_size = hidden_size\n        \n        layers.append(nn.Linear(in_size, n_classes))\n        self.network = nn.Sequential(*layers)\n    \n    def forward(self, x):\n        return self.network(x)\n\n\ndef create_objective(X_train_t, y_train_t, X_val_t, y_val_t, n_features, n_classes, \n                     class_weights_tensor, device, n_epochs=30):\n    \"\"\"\n    Create Optuna objective function for hyperparameter tuning.\n    \"\"\"\n    \n    def objective(trial):\n        # Suggest hyperparameters\n        n_layers = trial.suggest_int('n_layers', 1, 4)\n        hidden_sizes = []\n        for i in range(n_layers):\n            hidden_sizes.append(trial.suggest_int(f'hidden_size_l{i}', 32, 256, step=32))\n        \n        dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n        lr = trial.suggest_float('learning_rate', 1e-4, 1e-2, log=True)\n        batch_size = trial.suggest_categorical('batch_size', [32, 64, 128])\n        \n        # Create data loaders with suggested batch size\n        train_dataset = TensorDataset(X_train_t, y_train_t)\n        val_dataset = TensorDataset(X_val_t, y_val_t)\n        \n        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n        val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n        \n        # Create model\n        model = FlexibleNN(n_features, n_classes, hidden_sizes, dropout_rate).to(device)\n        \n        criterion = nn.CrossEntropyLoss(weight=class_weights_tensor)\n        optimizer = optim.Adam(model.parameters(), lr=lr)\n        \n        # Training loop with early stopping\n        best_val_f1 = 0\n        patience_counter = 0\n        \n        for epoch in range(n_epochs):\n            # Train\n            model.train()\n            for batch_X, batch_y in train_loader:\n                batch_X = batch_X.to(device)\n                batch_y = batch_y.to(device)\n                \n                optimizer.zero_grad()\n                outputs = model(batch_X)\n                loss = criterion(outputs, batch_y)\n                loss.backward()\n                optimizer.step()\n            \n            # Validate\n            model.eval()\n            all_preds = []\n            all_labels = []\n            \n            with torch.no_grad():\n                for batch_X, batch_y in val_loader:\n                    batch_X = batch_X.to(device)\n                    batch_y = batch_y.to(device)\n                    outputs = model(batch_X)\n                    preds = outputs.argmax(dim=1)\n                    all_preds.extend(preds.cpu().numpy())\n                    all_labels.extend(batch_y.cpu().numpy())\n            \n            val_f1 = f1_score(all_labels, all_preds, average='macro')\n            \n            # Report intermediate value for pruning\n            trial.report(val_f1, epoch)\n            \n            # Prune if needed\n            if trial.should_prune():\n                raise optuna.TrialPruned()\n            \n            # Track best\n            if val_f1 > best_val_f1:\n                best_val_f1 = val_f1\n                patience_counter = 0\n            else:\n                patience_counter += 1\n                if patience_counter >= 5:  # Shorter patience for tuning\n                    break\n        \n        return best_val_f1\n    \n    return objective",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Run Optuna hyperparameter search\nN_TRIALS = 20  # Increase for better results (50-100 recommended)\n\nprint(f\"Running Optuna hyperparameter search ({N_TRIALS} trials)...\")\nprint(\"This may take a few minutes...\\n\")\n\n# Create study\nstudy = optuna.create_study(\n    direction='maximize',  # Maximize F1 score\n    sampler=optuna.samplers.TPESampler(seed=42),\n    pruner=optuna.pruners.MedianPruner(n_startup_trials=5, n_warmup_steps=10)\n)\n\n# Create objective function\nobjective = create_objective(\n    X_train_tensor, y_train_tensor, X_val_tensor, y_val_tensor,\n    n_features, 3, class_weights_tensor, device, n_epochs=30\n)\n\n# Optimize\nstudy.optimize(objective, n_trials=N_TRIALS, show_progress_bar=True)\n\nprint(f\"\\nOptimization complete!\")\nprint(f\"Best trial F1: {study.best_trial.value:.4f}\")\nprint(f\"\\nBest hyperparameters:\")\nfor key, value in study.best_trial.params.items():\n    print(f\"  {key}: {value}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Visualize optimization history\nfig, axes = plt.subplots(1, 2, figsize=(12, 4))\n\n# Optimization history\ntrials_df = study.trials_dataframe()\ncompleted = trials_df[trials_df['state'] == 'COMPLETE']\n\naxes[0].scatter(completed.index, completed['value'], alpha=0.6)\naxes[0].axhline(y=study.best_trial.value, color='r', linestyle='--', label=f'Best: {study.best_trial.value:.4f}')\naxes[0].set_xlabel('Trial')\naxes[0].set_ylabel('Validation F1')\naxes[0].set_title('Optuna Optimization History')\naxes[0].legend()\naxes[0].grid(True, alpha=0.3)\n\n# Parameter importance (if enough trials)\nif len(completed) >= 10:\n    try:\n        importances = optuna.importance.get_param_importances(study)\n        params = list(importances.keys())[:6]  # Top 6\n        values = [importances[p] for p in params]\n        axes[1].barh(params, values)\n        axes[1].set_xlabel('Importance')\n        axes[1].set_title('Hyperparameter Importance')\n    except:\n        axes[1].text(0.5, 0.5, 'Not enough trials\\nfor importance analysis', \n                     ha='center', va='center', transform=axes[1].transAxes)\nelse:\n    axes[1].text(0.5, 0.5, 'Need more trials\\nfor importance analysis', \n                 ha='center', va='center', transform=axes[1].transAxes)\n\nplt.tight_layout()\nplt.show()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### 8.1 Train Final Model with Best Hyperparameters",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Extract best hyperparameters\nbest_params = study.best_trial.params\nprint(\"Training final model with best hyperparameters:\")\nprint(\"-\" * 40)\n\n# Build hidden sizes list\nn_layers = best_params['n_layers']\nhidden_sizes = [best_params[f'hidden_size_l{i}'] for i in range(n_layers)]\nprint(f\"Architecture: {n_features} -> {' -> '.join(map(str, hidden_sizes))} -> 3\")\nprint(f\"Dropout: {best_params['dropout_rate']:.2f}\")\nprint(f\"Learning rate: {best_params['learning_rate']:.6f}\")\nprint(f\"Batch size: {best_params['batch_size']}\")\nprint(\"-\" * 40)\n\n# Create best model\nbest_model = FlexibleNN(n_features, 3, hidden_sizes, best_params['dropout_rate']).to(device)\n\n# Create data loaders with best batch size\nbest_batch_size = best_params['batch_size']\nbest_train_loader = DataLoader(train_dataset, batch_size=best_batch_size, shuffle=True, drop_last=True)\nbest_val_loader = DataLoader(val_dataset, batch_size=best_batch_size, shuffle=False)\nbest_test_loader = DataLoader(test_dataset, batch_size=best_batch_size, shuffle=False)\n\n# Training setup\nbest_criterion = nn.CrossEntropyLoss(weight=class_weights_tensor)\nbest_optimizer = optim.Adam(best_model.parameters(), lr=best_params['learning_rate'])\n\n# Train with early stopping (longer training for final model)\nbest_train_losses = []\nbest_val_losses = []\nbest_val_f1s = []\nbest_model_state = None\nbest_f1 = 0\npatience_counter = 0\n\nprint(\"\\nTraining...\")\nfor epoch in range(100):  # More epochs for final model\n    # Train\n    best_model.train()\n    epoch_loss = 0\n    for batch_X, batch_y in best_train_loader:\n        batch_X = batch_X.to(device)\n        batch_y = batch_y.to(device)\n        \n        best_optimizer.zero_grad()\n        outputs = best_model(batch_X)\n        loss = best_criterion(outputs, batch_y)\n        loss.backward()\n        best_optimizer.step()\n        epoch_loss += loss.item()\n    \n    best_train_losses.append(epoch_loss / len(best_train_loader))\n    \n    # Validate\n    best_model.eval()\n    val_loss = 0\n    all_preds, all_labels = [], []\n    \n    with torch.no_grad():\n        for batch_X, batch_y in best_val_loader:\n            batch_X = batch_X.to(device)\n            batch_y = batch_y.to(device)\n            outputs = best_model(batch_X)\n            val_loss += best_criterion(outputs, batch_y).item()\n            all_preds.extend(outputs.argmax(dim=1).cpu().numpy())\n            all_labels.extend(batch_y.cpu().numpy())\n    \n    best_val_losses.append(val_loss / len(best_val_loader))\n    val_f1 = f1_score(all_labels, all_preds, average='macro')\n    best_val_f1s.append(val_f1)\n    \n    if val_f1 > best_f1:\n        best_f1 = val_f1\n        best_model_state = best_model.state_dict().copy()\n        patience_counter = 0\n        if (epoch + 1) % 10 == 0:\n            print(f\"Epoch {epoch+1}: F1 = {val_f1:.4f} ✓\")\n    else:\n        patience_counter += 1\n        if patience_counter >= 15:\n            print(f\"Early stopping at epoch {epoch+1}\")\n            break\n\nbest_model.load_state_dict(best_model_state)\nprint(f\"\\nBest validation F1: {best_f1:.4f}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Final evaluation on test set\nbest_model.eval()\nall_preds, all_labels, all_probs = [], [], []\n\nwith torch.no_grad():\n    for batch_X, batch_y in best_test_loader:\n        batch_X = batch_X.to(device)\n        batch_y = batch_y.to(device)\n        outputs = best_model(batch_X)\n        probs = torch.softmax(outputs, dim=1)\n        all_preds.extend(outputs.argmax(dim=1).cpu().numpy())\n        all_labels.extend(batch_y.cpu().numpy())\n        all_probs.extend(probs.cpu().numpy())\n\ny_pred_best = np.array(all_preds)\ny_true_best = np.array(all_labels)\ny_probs_best = np.array(all_probs)\n\n# Calculate metrics\nf1_best = f1_score(y_true_best, y_pred_best, average='macro')\nroc_auc_best = roc_auc_score(y_true_best, y_probs_best, multi_class='ovr')\nacc_best = np.mean(y_pred_best == y_true_best)\n\n# Final comparison table\nprint(\"=\" * 70)\nprint(\"FINAL MODEL COMPARISON (Test Set)\")\nprint(\"=\" * 70)\nprint(f\"{'Model':<40} {'F1 Macro':>10} {'ROC AUC':>10} {'Accuracy':>10}\")\nprint(\"-\" * 70)\nprint(f\"{'LightGBM (with labs)':<40} {lgb_results['f1_macro']:>10.4f} {lgb_results['roc_auc_ovr']:>10.4f} {lgb_results['accuracy']:>10.4f}\")\nprint(f\"{'MLP sklearn (with labs)':<40} {mlp_results['f1_macro']:>10.4f} {mlp_results['roc_auc_ovr']:>10.4f} {mlp_results['accuracy']:>10.4f}\")\nprint(\"-\" * 70)\nprint(f\"{'PyTorch (manual architecture)':<40} {f1_macro:>10.4f} {roc_auc:>10.4f} {test_acc:>10.4f}\")\nprint(f\"{'PyTorch (with OneCycleLR)':<40} {f1_sched:>10.4f} {roc_auc_sched:>10.4f} {acc_sched:>10.4f}\")\nprint(f\"{'PyTorch (Optuna-tuned)':<40} {f1_best:>10.4f} {roc_auc_best:>10.4f} {acc_best:>10.4f}\")\nprint(\"=\" * 70)\n\nprint(\"\\nClassification Report (Optuna-tuned model):\")\nprint(classification_report(y_true_best, y_pred_best, target_names=['No Diabetes', 'Prediabetes', 'Diabetes']))",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "---\n\n## Summary\n\n### What We Built\n\n| Part | Topic | Key Concepts |\n|------|-------|--------------|\n| 1-3 | Basic Classification | Tensors, DataLoaders, nn.Module, training loop |\n| 4-5 | Evaluation & Saving | Metrics, confusion matrix, model serialization |\n| 6 | Regression | MSELoss, continuous predictions, R² metric |\n| 7 | LR Scheduling | OneCycleLR, warmup, annealing |\n| 8 | Hyperparameter Tuning | Optuna, TPE sampler, pruning, search space |\n\n### Key Takeaways\n\n1. **LightGBM still wins for tabular data** - This is expected and well-documented in ML literature\n2. **Neural networks benefit from tuning** - Manual architecture vs Optuna-tuned can differ significantly\n3. **Learning rate scheduling helps** - OneCycleLR often improves convergence\n4. **Regression is harder than classification** - Lower R² indicates HbA1c is difficult to predict\n5. **Deep learning needs more data** - With ~8K samples, gradient boosting has advantage\n\n### Techniques Learned\n\n| Technique | Why It Helps |\n|-----------|--------------|\n| **BatchNorm** | Stabilizes training, allows higher LR |\n| **Dropout** | Prevents overfitting |\n| **Early stopping** | Prevents overfitting, saves time |\n| **Class weights** | Handles imbalanced classes |\n| **OneCycleLR** | Better convergence, often better final performance |\n| **Optuna** | Efficient hyperparameter search |\n\n### When to Use Neural Networks vs Gradient Boosting\n\n| Use Case | Recommendation |\n|----------|----------------|\n| Tabular data, <50K samples | Gradient Boosting (LightGBM, XGBoost) |\n| Tabular data, >100K samples | Can try neural networks |\n| Images, video | Neural networks (CNNs) |\n| Text, sequences | Neural networks (Transformers, RNNs) |\n| Audio | Neural networks |\n| Multi-modal (text+images) | Neural networks |\n\n### Next Steps (if continuing)\n\n- **Ensemble methods**: Combine LightGBM + PyTorch predictions\n- **Advanced architectures**: TabNet, FT-Transformer\n- **More data**: Expand to 1999-2018 NHANES\n- **Feature engineering**: Create more domain-specific features",
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}